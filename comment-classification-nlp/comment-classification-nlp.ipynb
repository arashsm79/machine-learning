{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Classifying Reddit comments that are about physics, chemistry and biology.\n",
    "- First, we preprocess the corpus using regex and nltk's tokenization and lemmatization\n",
    "- Then we use word2vec to create a representation for each word\n",
    "- after that, we cluster the representations in order to find the words that are close together in terms of their meaning\n",
    "- We then replace all the worlds of each cluster with the representative word of that cluster in the corpus. (this effectively makes sure that all the words in a cluster take the same spot in the bag of words vector.\n",
    "- Finally, we create a representation for each comment using bag of words and TF-IDF and try to classify the test data set.\n",
    "@arashsm79\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents:\n",
    "* [Pre-processing](#Pre-processing)\n",
    "* [Word2Vec](#Word2Vec)\n",
    "* [Clustering Word2Vec](#Clustering-Word2Vec)\n",
    "* [Bag-of-words and TF-IDF](#Bag-of-words-and-TF-IDF)\n",
    "* [Bag-of-words and TF-IDF with Word2Vec Topic Modeling](#-Bag-of-words-and-TF-IDF-with-Word2Vec-Topic-Modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x840</td>\n",
       "      <td>A few things. You might have negative- frequen...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xbf0</td>\n",
       "      <td>Is it so hard to believe that there exist part...</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1dfc</td>\n",
       "      <td>There are bees</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xc7e</td>\n",
       "      <td>I'm a medication technician. And that's alot o...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xbba</td>\n",
       "      <td>Cesium is such a pretty metal.</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                            Comment      Topic\n",
       "0   0x840  A few things. You might have negative- frequen...    Biology\n",
       "1   0xbf0  Is it so hard to believe that there exist part...    Physics\n",
       "2  0x1dfc                                     There are bees    Biology\n",
       "3   0xc7e  I'm a medication technician. And that's alot o...    Biology\n",
       "4   0xbba                     Cesium is such a pretty metal.  Chemistry"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train = pd.read_csv(\"train.csv\")\n",
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A few things. You might have negative- frequen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it so hard to believe that there exist part...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are bees</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm a medication technician. And that's alot o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cesium is such a pretty metal.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Topic\n",
       "0  A few things. You might have negative- frequen...      0\n",
       "1  Is it so hard to believe that there exist part...      2\n",
       "2                                     There are bees      0\n",
       "3  I'm a medication technician. And that's alot o...      0\n",
       "4                     Cesium is such a pretty metal.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numerical\n",
    "raw_train['Topic'] = LabelEncoder().fit_transform(raw_train['Topic'])\n",
    "\n",
    "# Drop the Id column\n",
    "raw_train = raw_train.drop(columns=[\"Id\"])\n",
    "\n",
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleanup_regex(txt: str) -> str:\n",
    "    # Convert to lower case and remove bounding space\n",
    "    txt = txt.lower().strip()\n",
    "    \n",
    "    # Remove reddit specific texts\n",
    "    txt = re.sub(\"\\[removed\\]\", \" \", txt)\n",
    "    txt = re.sub(\"\\[deleted\\]\", \" \", txt)\n",
    "    \n",
    "    # Remove URLs\n",
    "    txt = re.sub(\"http\\S+\", \" \", txt) \n",
    "    txt = re.sub(\"www\\.\\S+\", \" \", txt) \n",
    "\n",
    "    # Remove everything that is not a letter\n",
    "    txt = re.sub(\"[^a-zA-Z]\", \" \", txt)\n",
    "    # txt = re.sub('[%s]' % re.escape(string.punctuation), ' ', txt)\n",
    "    \n",
    "    # Remove single and double letter words    \n",
    "    txt = re.sub(r'\\b\\w{1,2}\\b', ' ', txt)\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_cleanup_pipeline(txt: str) -> [str]:\n",
    "    # basic clean up using regex\n",
    "    txt: str   = text_cleanup_regex(txt)\n",
    "    \n",
    "    # tokenize (convert string of words to array of words)\n",
    "    txt: [str] = word_tokenize(txt)\n",
    "    \n",
    "    # make sure the word is not a stopword\n",
    "    txt: [str] = [w for w in txt if w not in english_stopwords]\n",
    "    \n",
    "    # take  out the root of the word\n",
    "    txt: [str] = [lemmatizer.lemmatize(w) for w in txt]\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[thing, might, negative, frequency, dependent,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hard, believe, exist, particular, detect, any...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bee]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[medication, technician, alot, drug, liver, pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[cesium, pretty, metal]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Topic\n",
       "0  [thing, might, negative, frequency, dependent,...      0\n",
       "1  [hard, believe, exist, particular, detect, any...      2\n",
       "2                                              [bee]      0\n",
       "3  [medication, technician, alot, drug, liver, pr...      0\n",
       "4                            [cesium, pretty, metal]      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up comments using text_cleanup_pipeline\n",
    "raw_train['Comment'] = raw_train['Comment'].apply(lambda x : text_cleanup_pipeline(x))\n",
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 286\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[thing, might, negative, frequency, dependent,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hard, believe, exist, particular, detect, any...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bee]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[medication, technician, alot, drug, liver, pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[cesium, pretty, metal]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Topic\n",
       "0  [thing, might, negative, frequency, dependent,...      0\n",
       "1  [hard, believe, exist, particular, detect, any...      2\n",
       "2                                              [bee]      0\n",
       "3  [medication, technician, alot, drug, liver, pr...      0\n",
       "4                            [cesium, pretty, metal]      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with empty comment\n",
    "size_before_empty_drop = raw_train.shape[0]\n",
    "raw_train = raw_train[raw_train['Comment'].apply(lambda x: len(x) > 0)]\n",
    "print(\"Dropped: {}\".format(size_before_empty_drop - raw_train.shape[0]))\n",
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thing might negative frequency dependent selec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard believe exist particular detect anything ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bee</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medication technician alot drug liver probably...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cesium pretty metal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Topic\n",
       "0  thing might negative frequency dependent selec...      0\n",
       "1  hard believe exist particular detect anything ...      2\n",
       "2                                                bee      0\n",
       "3  medication technician alot drug liver probably...      0\n",
       "4                                cesium pretty metal      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert list of words to string\n",
    "raw_train['Comment'] = raw_train['Comment'].apply(lambda x : \" \".join(x))\n",
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same preprocessing for train data\n",
    "raw_test = pd.read_csv(\"test.csv\")\n",
    "raw_test['Topic'] = LabelEncoder().fit_transform(raw_test['Topic'])\n",
    "raw_test = raw_test.drop(columns=[\"Id\"])\n",
    "raw_test['Comment'] = raw_test['Comment'].apply(lambda x : text_cleanup_pipeline(x))\n",
    "raw_test = raw_test[raw_test['Comment'].apply(lambda x: len(x) > 0)]\n",
    "raw_test['Comment'] = raw_test['Comment'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid having to preprocess the data again in case something goes wrong, copy the preprocessed data to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8409, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = raw_train.copy()\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1586, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = raw_test.copy()\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take out the unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 14574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['abbreviation', 'abd', 'abdomen', 'abdominal', 'abduction',\n",
       "       'abetted', 'abhor', 'abi', 'ability', 'abiotic'], dtype='<U46')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words: [str] = list(set(\" \".join(train_data['Comment'].str.lower().values.tolist()).split(\" \")))\n",
    "unique_words.sort()\n",
    "print(\"Size: {}\".format(len(unique_words)))\n",
    "unique_words: np.ndarray = np.array(unique_words)\n",
    "unique_words[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get a list o unique words\n",
    "* Use googles trained W2V to get a vector for each word\n",
    "* Create a dataframe and combine the words with their vectors\n",
    "* Save te data frame to avoid loading the 1.5 Gb model everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 12164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['abhor', 'abi', 'ability', 'abiotic', 'abject', 'able', 'abnormal',\n",
       "       'abolish', 'abomination', 'abort'], dtype='<U46')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select words that have a vector\n",
    "unique_words = np.fromiter((x for x in unique_words if model.has_index_for(x)), dtype=unique_words.dtype)\n",
    "print(\"Size: {}\".format(len(unique_words)))\n",
    "unique_words[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12164, 300)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the corresponding vector for each word\n",
    "unique_words_vectors = np.array(list(map(lambda x: model[x], unique_words)))\n",
    "unique_words_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaa</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>-0.113281</td>\n",
       "      <td>-0.337891</td>\n",
       "      <td>0.082520</td>\n",
       "      <td>-0.208984</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>-0.138672</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.106934</td>\n",
       "      <td>-0.031982</td>\n",
       "      <td>-0.191406</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>-0.376953</td>\n",
       "      <td>0.168945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aah</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>-0.010132</td>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.229492</td>\n",
       "      <td>-0.070801</td>\n",
       "      <td>-0.458984</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>-0.213867</td>\n",
       "      <td>0.150391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002899</td>\n",
       "      <td>0.392578</td>\n",
       "      <td>-0.214844</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>-0.200195</td>\n",
       "      <td>-0.236328</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>-0.296875</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ab</td>\n",
       "      <td>0.064941</td>\n",
       "      <td>0.241211</td>\n",
       "      <td>0.054443</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>-0.075684</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>-0.051514</td>\n",
       "      <td>-0.163086</td>\n",
       "      <td>-0.243164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>-0.139648</td>\n",
       "      <td>-0.055176</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>-0.159180</td>\n",
       "      <td>-0.081543</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>-0.051025</td>\n",
       "      <td>0.047607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0.007660</td>\n",
       "      <td>0.078613</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>-0.208984</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>-0.036621</td>\n",
       "      <td>-0.041992</td>\n",
       "      <td>0.192383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033203</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>-0.205078</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>-0.089355</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.141602</td>\n",
       "      <td>0.107910</td>\n",
       "      <td>0.259766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>-0.209961</td>\n",
       "      <td>0.138672</td>\n",
       "      <td>0.386719</td>\n",
       "      <td>-0.277344</td>\n",
       "      <td>-0.208008</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.376953</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020020</td>\n",
       "      <td>-0.084473</td>\n",
       "      <td>-0.120117</td>\n",
       "      <td>-0.167969</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>-0.183594</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>-0.114746</td>\n",
       "      <td>-0.515625</td>\n",
       "      <td>0.416016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word         0         1         2         3         4         5  \\\n",
       "0           aaa  0.031738  0.021973  0.041016  0.328125 -0.113281 -0.337891   \n",
       "1           aah  0.163086 -0.010132  0.105957  0.229492 -0.070801 -0.458984   \n",
       "2            ab  0.064941  0.241211  0.054443  0.191406 -0.075684  0.199219   \n",
       "3       abandon  0.007660  0.078613  0.109375  0.339844 -0.208984  0.044678   \n",
       "4  abbreviation  0.218750 -0.209961  0.138672  0.386719 -0.277344 -0.208008   \n",
       "\n",
       "          6         7         8  ...       290       291       292       293  \\\n",
       "0  0.082520 -0.208984  0.410156  ...  0.044922  0.449219 -0.138672 -0.267578   \n",
       "1  0.206055 -0.213867  0.150391  ... -0.002899  0.392578 -0.214844 -0.006042   \n",
       "2 -0.051514 -0.163086 -0.243164  ...  0.068359  0.042969 -0.139648 -0.055176   \n",
       "3 -0.036621 -0.041992  0.192383  ... -0.033203  0.355469 -0.205078  0.080566   \n",
       "4 -0.382812 -0.376953  0.161133  ... -0.020020 -0.084473 -0.120117 -0.167969   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.106934 -0.031982 -0.191406  0.018188 -0.376953  0.168945  \n",
       "1 -0.200195 -0.236328  0.151367 -0.296875 -0.117188  0.250000  \n",
       "2  0.062500 -0.159180 -0.081543  0.337891 -0.051025  0.047607  \n",
       "3 -0.137695 -0.089355  0.199219  0.141602  0.107910  0.259766  \n",
       "4  0.152344 -0.183594  0.047852 -0.114746 -0.515625  0.416016  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zip words and vectors together\n",
    "word_vecs = pd.DataFrame(unique_words_vectors)\n",
    "word_vecs.insert(loc=0, column='word', value=unique_words)\n",
    "word_vecs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a file\n",
    "word_vecs.to_pickle(\"reddit_w2v.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaa</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>-0.113281</td>\n",
       "      <td>-0.337891</td>\n",
       "      <td>0.082520</td>\n",
       "      <td>-0.208984</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>-0.138672</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.106934</td>\n",
       "      <td>-0.031982</td>\n",
       "      <td>-0.191406</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>-0.376953</td>\n",
       "      <td>0.168945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aah</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>-0.010132</td>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.229492</td>\n",
       "      <td>-0.070801</td>\n",
       "      <td>-0.458984</td>\n",
       "      <td>0.206055</td>\n",
       "      <td>-0.213867</td>\n",
       "      <td>0.150391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002899</td>\n",
       "      <td>0.392578</td>\n",
       "      <td>-0.214844</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>-0.200195</td>\n",
       "      <td>-0.236328</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>-0.296875</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ab</td>\n",
       "      <td>0.064941</td>\n",
       "      <td>0.241211</td>\n",
       "      <td>0.054443</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>-0.075684</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>-0.051514</td>\n",
       "      <td>-0.163086</td>\n",
       "      <td>-0.243164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>-0.139648</td>\n",
       "      <td>-0.055176</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>-0.159180</td>\n",
       "      <td>-0.081543</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>-0.051025</td>\n",
       "      <td>0.047607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0.007660</td>\n",
       "      <td>0.078613</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>-0.208984</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>-0.036621</td>\n",
       "      <td>-0.041992</td>\n",
       "      <td>0.192383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033203</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>-0.205078</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>-0.089355</td>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.141602</td>\n",
       "      <td>0.107910</td>\n",
       "      <td>0.259766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>-0.209961</td>\n",
       "      <td>0.138672</td>\n",
       "      <td>0.386719</td>\n",
       "      <td>-0.277344</td>\n",
       "      <td>-0.208008</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.376953</td>\n",
       "      <td>0.161133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020020</td>\n",
       "      <td>-0.084473</td>\n",
       "      <td>-0.120117</td>\n",
       "      <td>-0.167969</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>-0.183594</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>-0.114746</td>\n",
       "      <td>-0.515625</td>\n",
       "      <td>0.416016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word         0         1         2         3         4         5  \\\n",
       "0           aaa  0.031738  0.021973  0.041016  0.328125 -0.113281 -0.337891   \n",
       "1           aah  0.163086 -0.010132  0.105957  0.229492 -0.070801 -0.458984   \n",
       "2            ab  0.064941  0.241211  0.054443  0.191406 -0.075684  0.199219   \n",
       "3       abandon  0.007660  0.078613  0.109375  0.339844 -0.208984  0.044678   \n",
       "4  abbreviation  0.218750 -0.209961  0.138672  0.386719 -0.277344 -0.208008   \n",
       "\n",
       "          6         7         8  ...       290       291       292       293  \\\n",
       "0  0.082520 -0.208984  0.410156  ...  0.044922  0.449219 -0.138672 -0.267578   \n",
       "1  0.206055 -0.213867  0.150391  ... -0.002899  0.392578 -0.214844 -0.006042   \n",
       "2 -0.051514 -0.163086 -0.243164  ...  0.068359  0.042969 -0.139648 -0.055176   \n",
       "3 -0.036621 -0.041992  0.192383  ... -0.033203  0.355469 -0.205078  0.080566   \n",
       "4 -0.382812 -0.376953  0.161133  ... -0.020020 -0.084473 -0.120117 -0.167969   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.106934 -0.031982 -0.191406  0.018188 -0.376953  0.168945  \n",
       "1 -0.200195 -0.236328  0.151367 -0.296875 -0.117188  0.250000  \n",
       "2  0.062500 -0.159180 -0.081543  0.337891 -0.051025  0.047607  \n",
       "3 -0.137695 -0.089355  0.199219  0.141602  0.107910  0.259766  \n",
       "4  0.152344 -0.183594  0.047852 -0.114746 -0.515625  0.416016  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataframe from a file\n",
    "output = pd.read_pickle(\"reddit_w2v.pkl\")\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='out.csv')\n",
    "output.to_csv(\"reddit_w2v.zip\", index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03173828,  0.02197266,  0.04101562, ...,  0.01818848,\n",
       "        -0.37695312,  0.16894531],\n",
       "       [ 0.16308594, -0.01013184,  0.10595703, ..., -0.296875  ,\n",
       "        -0.1171875 ,  0.25      ],\n",
       "       [ 0.06494141,  0.24121094,  0.05444336, ...,  0.33789062,\n",
       "        -0.05102539,  0.04760742],\n",
       "       ...,\n",
       "       [-0.07421875, -0.10205078,  0.20117188, ..., -0.25390625,\n",
       "         0.06054688, -0.21289062],\n",
       "       [ 0.18554688,  0.16894531,  0.00267029, ..., -0.33007812,\n",
       "         0.05004883, -0.21191406],\n",
       "       [-0.08935547,  0.10351562,  0.06787109, ...,  0.0378418 ,\n",
       "         0.05053711,  0.01940918]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = output['word']\n",
    "output: pd.DataFrame = output.iloc[:, 1:301]\n",
    "vectors = output.to_numpy()\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering-Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_vectors = PCA(n_components=2).fit_transform(vectors)\n",
    "pca_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_vectors = StandardScaler().fit_transform(pca_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_iden = KMeans(n_clusters=10000, random_state=0).fit(pca_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the clusters and print some of the clustered words\n",
    "for i in range(key_iden.n_clusters):\n",
    "    n = words[key_iden.labels_ == i].shape[0]\n",
    "    if n > 1 and n < 10:\n",
    "        print(words[key_iden.labels_ == i].shape)\n",
    "        print(words[key_iden.labels_ == i])\n",
    "        time.sleep(1)\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4269, 6165,  546, ..., 3362, 6058, 5095], dtype=int32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_iden.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ELEMENTS_UPPER_THRESHOLD = 10\n",
    "N_ELEMENTS_LOWER_THRESHOLD = 1\n",
    "\n",
    "# Find cluster numbers with proper number of elements\n",
    "good_cluster_numbers = []\n",
    "for i in range(key_iden.n_clusters):\n",
    "    n = words[key_iden.labels_ == i].shape[0]\n",
    "    if n > N_ELEMENTS_LOWER_THRESHOLD and n < N_ELEMENTS_UPPER_THRESHOLD:\n",
    "        good_cluster_numbers.append(i)\n",
    "\n",
    "# Find a representation for each cluster (here we take the first word)\n",
    "good_cluster_words = []\n",
    "for i in good_cluster_numbers:\n",
    "    good_cluster_words.append(words[key_iden.labels_ == i].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modeled_train_data = train_data.copy()\n",
    "for i, cluster_num in enumerate(good_cluster_numbers):\n",
    "    for word in words[key_iden.labels_ == cluster_num]:\n",
    "        topic_modeled_train_data['Comment'].replace(word, good_cluster_words[i], inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words: 14574\n",
      "Topic modeled unique words: 12961\n",
      "Diff: 1613\n"
     ]
    }
   ],
   "source": [
    "topic_modeled_unique_words: [str] = list(set(\" \".join(topic_modeled_train_data['Comment'].str.lower().values.tolist()).split(\" \")))\n",
    "print(\"Unique words: {}\".format(len(unique_words)))\n",
    "print(\"Topic modeled unique words: {}\".format(len(topic_modeled_unique_words)))\n",
    "print(\"Diff: {}\".format(len(unique_words) - len(topic_modeled_unique_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modeled_test_data = test_data.copy()\n",
    "for i, cluster_num in enumerate(good_cluster_numbers):\n",
    "    for word in words[key_iden.labels_ == cluster_num]:\n",
    "        topic_modeled_test_data['Comment'].replace(word, good_cluster_words[i], inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate labels\n",
    "x_train = train_data[\"Comment\"]\n",
    "y_train = train_data[\"Topic\"]\n",
    "\n",
    "x_test = test_data[\"Comment\"]\n",
    "y_test = test_data[\"Topic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_train = bow_vectorizer.fit_transform(x_train)\n",
    "bow_test = bow_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       614\n",
      "           1       0.79      0.85      0.82       506\n",
      "           2       0.84      0.86      0.85       466\n",
      "\n",
      "    accuracy                           0.84      1586\n",
      "   macro avg       0.84      0.85      0.84      1586\n",
      "weighted avg       0.85      0.84      0.84      1586\n",
      "\n",
      "Train Score: 0.8800095136163634\n",
      "Test Score: 0.8442622950819673\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(bow_train, y_train)\n",
    "y_pred = clf.predict(bow_test)\n",
    "\n",
    "# Classification score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Train Score: {}\".format(clf.score(bow_train, y_train)))\n",
    "print(\"Test Score: {}\".format(clf.score(bow_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       614\n",
      "           1       0.79      0.85      0.82       506\n",
      "           2       0.85      0.84      0.85       466\n",
      "\n",
      "    accuracy                           0.84      1586\n",
      "   macro avg       0.84      0.84      0.84      1586\n",
      "weighted avg       0.85      0.84      0.84      1586\n",
      "\n",
      "Train Score: 0.9086692829111666\n",
      "Test Score: 0.8430012610340479\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(tfidf_train, y_train)\n",
    "y_pred = clf.predict(tfidf_test)\n",
    "\n",
    "# Classification score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Train Score: {}\".format(clf.score(tfidf_train, y_train)))\n",
    "print(\"Test Score: {}\".format(clf.score(tfidf_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words and TF-IDF with Word2Vec Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate labels\n",
    "x_train = topic_modeled_train_data[\"Comment\"]\n",
    "y_train = topic_modeled_train_data[\"Topic\"]\n",
    "\n",
    "x_test = topic_modeled_test_data[\"Comment\"]\n",
    "y_test = topic_modeled_test_data[\"Topic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_train = bow_vectorizer.fit_transform(x_train)\n",
    "bow_test = bow_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85       614\n",
      "           1       0.79      0.84      0.81       506\n",
      "           2       0.84      0.87      0.86       466\n",
      "\n",
      "    accuracy                           0.84      1586\n",
      "   macro avg       0.84      0.84      0.84      1586\n",
      "weighted avg       0.84      0.84      0.84      1586\n",
      "\n",
      "Train Score: 0.8741824235937686\n",
      "Test Score: 0.8417402269861286\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(bow_train, y_train)\n",
    "y_pred = clf.predict(bow_test)\n",
    "\n",
    "# Classification score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Train Score: {}\".format(clf.score(bow_train, y_train)))\n",
    "print(\"Test Score: {}\".format(clf.score(bow_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       614\n",
      "           1       0.79      0.85      0.82       506\n",
      "           2       0.85      0.86      0.86       466\n",
      "\n",
      "    accuracy                           0.84      1586\n",
      "   macro avg       0.84      0.84      0.84      1586\n",
      "weighted avg       0.84      0.84      0.84      1586\n",
      "\n",
      "Train Score: 0.904150315138542\n",
      "Test Score: 0.8398486759142497\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(tfidf_train, y_train)\n",
    "y_pred = clf.predict(tfidf_test)\n",
    "\n",
    "# Classification score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Train Score: {}\".format(clf.score(tfidf_train, y_train)))\n",
    "print(\"Test Score: {}\".format(clf.score(tfidf_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 - mach-nix-jupyter",
   "language": "python",
   "name": "ipython_mach-nix-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
